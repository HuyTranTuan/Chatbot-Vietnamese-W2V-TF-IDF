{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def switch_chude(var):\n",
    "    switcher = {\n",
    "                1: \"data_final\\\\bạn bè.txt\", \n",
    "                2: \"data_final\\\\các câu hỏi phức tạp.txt\", \n",
    "                3: \"data_final\\\\đất nước.txt\",\n",
    "                4: \"data_final\\\\địa chỉ.txt\", \n",
    "                5: \"data_final\\\\du lịch.txt\", \n",
    "                6: \"data_final\\\\gia đình.txt\", \n",
    "                7: \"data_final\\\\giải trí.txt\", \n",
    "                8: \"data_final\\\\học tập.txt\", \n",
    "                9: \"data_final\\\\nghề nghiệp.txt\", \n",
    "                10: \"data_final\\\\nghi lễ.txt\", \n",
    "                11: \"data_final\\\\người yêu.txt\", \n",
    "                12: \"data_final\\\\robot.txt\", \n",
    "                13: \"data_final\\\\shopping.txt\", \n",
    "                14: \"data_final\\\\sở thích.txt\", \n",
    "                15: \"data_final\\\\tán gẫu.txt\", \n",
    "                16: \"data_final\\\\tdtu.txt\", \n",
    "                17: \"data_final\\\\thông tin cá nhân.txt\", \n",
    "                18: \"data_final\\\\trò chuyện về đi ăn.txt\"\n",
    "    }\n",
    "\n",
    "    return switcher.get(var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Bạn bè   2.Các câu hỏi phức tạp   3.Đất nước   4.Địa chỉ   5.Du lịch   6.Gia đình\n",
      "7.Giải trí   8.Học tập   9.Nghề nghiệp   10.Nghi lễ   11.Người yêu   12.Robot\n",
      "13.Shopping   14.Sở thích   15.Tán ngẫu   16.TDTU   17.Thông tin cá nhân   18.Trò chuyện về đi ăn\n",
      "\n",
      "Chọn chủ đề: 17\n"
     ]
    }
   ],
   "source": [
    "print('1.Bạn bè   2.Các câu hỏi phức tạp   3.Đất nước   4.Địa chỉ   5.Du lịch   6.Gia đình')\n",
    "print('7.Giải trí   8.Học tập   9.Nghề nghiệp   10.Nghi lễ   11.Người yêu   12.Robot')\n",
    "print('13.Shopping   14.Sở thích   15.Tán ngẫu   16.TDTU   17.Thông tin cá nhân   18.Trò chuyện về đi ăn\\n')\n",
    "\n",
    "subject = int(input('Chọn chủ đề: '))\n",
    "while subject<1 or subject>18:\n",
    "    subject = int(input('Chọn lại chủ đề: '))\n",
    "    \n",
    "path = switch_chude(subject)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_sent=[]\n",
    "with open(path, encoding=\"utf8\") as f:\n",
    "    train_lines = f.readlines()\n",
    "    for line in train_lines:\n",
    "        line = line.split('__eou__')\n",
    "        line.remove('\\n')\n",
    "        for i in range(len(line)):\n",
    "            line[i] = line[i].strip()\n",
    "        list_sent.append(line)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>questions</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>họ và tên của bạn là gì ?</td>\n",
       "      <td>họ và tên của mình là Hà Công Thành</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bạn bao nhiêu tuổi rồi ?</td>\n",
       "      <td>mình năm nay 22 tuổi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bạn đang đi làm hay đang đi học ?</td>\n",
       "      <td>mình đang học tại trường đại học Tôn Đức Thắng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bạn cao bao nhiêu ?</td>\n",
       "      <td>mình cao 1 mét 63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sở thích của bạn là gì ?</td>\n",
       "      <td>sở thích của mình là chơi game và xem phim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>770</th>\n",
       "      <td>Bạn cho mình hỏi bạn tên gì ?</td>\n",
       "      <td>Hiếu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>Bạn bao nhiêu tuổi ?</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>772</th>\n",
       "      <td>Bạn cho mình hỏi bạn là nam hay nữ ?</td>\n",
       "      <td>nam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>773</th>\n",
       "      <td>Bạn cho mình hỏi bạn học ở đâu ?</td>\n",
       "      <td>TDTU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>774</th>\n",
       "      <td>Bạn cho mình hỏi bạn SDT của bạn ?</td>\n",
       "      <td>0902622737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>775 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                questions  \\\n",
       "0               họ và tên của bạn là gì ?   \n",
       "1                bạn bao nhiêu tuổi rồi ?   \n",
       "2       bạn đang đi làm hay đang đi học ?   \n",
       "3                     bạn cao bao nhiêu ?   \n",
       "4                sở thích của bạn là gì ?   \n",
       "..                                    ...   \n",
       "770         Bạn cho mình hỏi bạn tên gì ?   \n",
       "771                  Bạn bao nhiêu tuổi ?   \n",
       "772  Bạn cho mình hỏi bạn là nam hay nữ ?   \n",
       "773      Bạn cho mình hỏi bạn học ở đâu ?   \n",
       "774    Bạn cho mình hỏi bạn SDT của bạn ?   \n",
       "\n",
       "                                            answers  \n",
       "0               họ và tên của mình là Hà Công Thành  \n",
       "1                              mình năm nay 22 tuổi  \n",
       "2    mình đang học tại trường đại học Tôn Đức Thắng  \n",
       "3                                 mình cao 1 mét 63  \n",
       "4        sở thích của mình là chơi game và xem phim  \n",
       "..                                              ...  \n",
       "770                                            Hiếu  \n",
       "771                                              22  \n",
       "772                                             nam  \n",
       "773                                            TDTU  \n",
       "774                                      0902622737  \n",
       "\n",
       "[775 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_Question = []\n",
    "for i in list_sent:\n",
    "    get_Question.append(i[0])\n",
    "\n",
    "get_Answer = []\n",
    "for i in list_sent:\n",
    "    get_Answer.append(i[1])\n",
    "    \n",
    "df = pd.DataFrame({\"questions\": get_Question, \"answers\": get_Answer})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list of libraries used by the code\n",
    "import string\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import math\n",
    "import random\n",
    "from math import *\n",
    "\n",
    "def tokenizeWord(sentences):\n",
    "  sents=[]\n",
    "  for sentence in sentences:\n",
    "    newSent = sentence.lower()\n",
    "    newSent = re.sub(r\"[\\.,\\?]+$\", \"\", newSent)\n",
    "    tokens = nltk.word_tokenize(newSent)\n",
    "    sents.append(tokens)\n",
    "  return sents\n",
    "\n",
    "tokenizeQuestion = tokenizeWord(df['questions'].tolist())\n",
    "tokenizeAnswer = tokenizeWord(df['answers'].tolist())\n",
    "tokenize = []\n",
    "tokenize.extend(tokenizeQuestion)\n",
    "tokenize.extend(tokenizeAnswer)\n",
    "\n",
    "modelw2v = Word2Vec(sentences=tokenize, vector_size=100, window=5, sg=1, min_count=2)\n",
    "\n",
    "def cosine_similarity1(v1, v2):\n",
    "  num = np.dot(v1, v2)\n",
    "  d1 = np.dot(v1, v1)\n",
    "  d2 = np.dot(v2, v2)\n",
    "  if d1 > 0.0 and d2 > 0.0:\n",
    "    return num / math.sqrt(d1 * d2)\n",
    "  else:\n",
    "    return 0.0\n",
    "\n",
    "def embedding_word(words):\n",
    "  vectors = [modelw2v.wv[word] for word in words if word in modelw2v.wv]\n",
    "  if vectors:\n",
    "    return np.average(vectors, axis=0)\n",
    "  else:\n",
    "    return np.zeros(modelw2v.wv.vector_size)\n",
    "\n",
    "def compare_question(question_input, question_in_df):\n",
    "  q_input = {word for word in gensim.utils.simple_preprocess(question_input)}\n",
    "  q_in_df = {word for word in gensim.utils.simple_preprocess(question_in_df) }\n",
    "  return cosine_similarity1(embedding_word(q_input), embedding_word(q_in_df))\n",
    "\n",
    "def getAns(question_input):\n",
    "    get_cosime = []\n",
    "    for i in range(len(get_Question)):\n",
    "        get_cosime.append(compare_question(question_input, get_Question[i]))\n",
    "\n",
    "    result = max(get_cosime)\n",
    "\n",
    "    ans=[]\n",
    "    for i in range(len(get_cosime)):\n",
    "        if get_cosime[i] == result:\n",
    "            ans.append(get_Answer[i])\n",
    "\n",
    "    print(\"Word2Vec: \",random.choice(ans))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer.fit_transform(df['questions'].tolist())\n",
    "\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "def getCosineSimilarity(q1, q2):\n",
    "  tfidf_q1 = vectorizer.transform([q1])\n",
    "  tfidf_q2 = vectorizer.transform([q2])\n",
    "  return linear_kernel(tfidf_q1, tfidf_q2).flatten()[0]\n",
    "\n",
    "def getAnswer(q):\n",
    "  max_score = 0\n",
    "  answer = ''\n",
    "  for idx, row in df.iterrows():\n",
    "    score = getCosineSimilarity(q.lower(), row['questions'])\n",
    "    if score > max_score:\n",
    "      max_score = score\n",
    "      answer = row[\"answers\"]\n",
    "  print(\"TF-IDF: \",answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input and print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nhập câu: thoat\n"
     ]
    }
   ],
   "source": [
    "while(True):\n",
    "    stringInput=str(input('Nhập câu: '))\n",
    "    if(stringInput.lower() == 'thoat' or stringInput.lower() == 'thoát'):\n",
    "        break\n",
    "    getAns(stringInput)\n",
    "    getAnswer(stringInput)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'yêu', 'người', 'chưa'}\n"
     ]
    }
   ],
   "source": [
    "q_input = {word for word in gensim.utils.simple_preprocess(\"người yêu chưa?\")}\n",
    "print(q_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03782536  0.0517998   0.06221983 -0.00494829 -0.06299109 -0.28582203\n",
      " -0.04181548  0.23627687 -0.0694603  -0.11514656 -0.10541163 -0.19475819\n",
      " -0.08800478 -0.05920701  0.10077775 -0.1353102   0.01631377 -0.18018511\n",
      " -0.01792094 -0.32390893 -0.00255154  0.11324304  0.18807998 -0.08453412\n",
      " -0.0162452   0.03139582 -0.18880665  0.02418373 -0.11717433  0.01045646\n",
      "  0.27076575  0.0728436   0.1586123  -0.16893718 -0.09163054  0.08328474\n",
      "  0.02327818 -0.05708412 -0.05641179 -0.15720096 -0.0447504  -0.11325675\n",
      " -0.08757935 -0.06104799  0.07068398 -0.1371267  -0.16750893 -0.03028401\n",
      "  0.14855859  0.0925623   0.05187007  0.00499872  0.06836873  0.06817614\n",
      " -0.00830157  0.11802836  0.10547975 -0.02276921 -0.09524318  0.2048295\n",
      "  0.04856482 -0.03295986 -0.04968133 -0.05766934 -0.08380578  0.11675487\n",
      "  0.01704728  0.14228927 -0.15982138  0.24900386 -0.08245738  0.09234434\n",
      "  0.16712289 -0.07558048  0.1861952   0.06477365  0.04248075 -0.0353619\n",
      " -0.02813539  0.00424471 -0.10157917  0.02374456 -0.08059159  0.28155997\n",
      " -0.12678084 -0.00742238  0.03312743  0.16431873  0.12923382  0.06014423\n",
      "  0.23419422  0.08412264  0.02611393 -0.03066336  0.18027858  0.11085801\n",
      " -0.03222649 -0.09205708 -0.057121   -0.07327817]\n",
      "[-0.03730994  0.04135075  0.04975227 -0.00971912 -0.06209721 -0.2846703\n",
      " -0.03832937  0.2576717  -0.05496931 -0.1379351  -0.08690058 -0.18227075\n",
      " -0.10132143 -0.07507196  0.10214992 -0.12558103  0.0033603  -0.1914508\n",
      " -0.01187873 -0.33502203 -0.00685755  0.12155941  0.19344743 -0.10148541\n",
      " -0.0081462   0.0256833  -0.19738086  0.02434873 -0.11042666  0.01681748\n",
      "  0.2764258   0.06161232  0.17657232 -0.17165138 -0.08957518  0.09357703\n",
      "  0.00833395 -0.05814688 -0.04894112 -0.16763419 -0.03807682 -0.11536202\n",
      " -0.08901286 -0.05903879  0.07468714 -0.14203717 -0.16155955 -0.01924378\n",
      "  0.14154877  0.10715637  0.05870295 -0.00565668  0.07335424  0.06845105\n",
      "  0.00332646  0.12665229  0.11852903 -0.00682575 -0.11201405  0.20994034\n",
      "  0.03703526 -0.02662027 -0.04163099 -0.05951934 -0.08382669  0.11276792\n",
      "  0.01895118  0.15687257 -0.16724849  0.24819398 -0.0777671   0.09870157\n",
      "  0.1787498  -0.07519464  0.1986463   0.05092972  0.03884509 -0.03963921\n",
      " -0.04130885  0.00208065 -0.08938999  0.03241495 -0.09742883  0.30400473\n",
      " -0.12636827 -0.00373953  0.04411091  0.16691633  0.12263704  0.07525334\n",
      "  0.23269276  0.08976988  0.02624469 -0.03004898  0.19017132  0.12801613\n",
      " -0.01860157 -0.09707009 -0.04348518 -0.08430663]\n",
      "[-4.54170667e-02  6.32036850e-02  5.41206300e-02 -3.58914444e-03\n",
      " -5.68594374e-02 -2.94998497e-01 -3.14338878e-02  2.66367346e-01\n",
      " -6.83381706e-02 -1.43699676e-01 -1.00337461e-01 -1.96858674e-01\n",
      " -1.03470102e-01 -7.32529834e-02  1.06710270e-01 -1.47807986e-01\n",
      "  1.26016876e-02 -1.85578659e-01 -2.43983865e-02 -3.38496745e-01\n",
      " -1.07552558e-02  1.21267624e-01  2.06746072e-01 -1.08441494e-01\n",
      " -1.93863548e-02  1.78436153e-02 -2.17266649e-01  9.24493372e-03\n",
      " -1.20105579e-01  1.14254961e-02  2.85974056e-01  6.33166358e-02\n",
      "  1.69293642e-01 -1.77153215e-01 -1.08137555e-01  9.87954512e-02\n",
      "  1.79433133e-02 -4.86995429e-02 -5.32994084e-02 -1.71123147e-01\n",
      " -4.26236205e-02 -1.05362520e-01 -8.07720423e-02 -5.10875024e-02\n",
      "  7.03245699e-02 -1.34936020e-01 -1.82326406e-01 -1.68096591e-02\n",
      "  1.52739391e-01  1.03970408e-01  7.31938854e-02 -3.40205571e-03\n",
      "  7.94479698e-02  5.33814877e-02 -1.72262527e-02  1.38897523e-01\n",
      "  1.26010269e-01 -5.98349608e-03 -1.23457283e-01  2.12033004e-01\n",
      "  5.16952723e-02 -2.45554112e-02 -5.00645600e-02 -6.05757795e-02\n",
      " -7.49453381e-02  1.07655987e-01 -2.56510713e-04  1.60850480e-01\n",
      " -1.65960789e-01  2.45657369e-01 -9.21254978e-02  1.04662947e-01\n",
      "  1.87310442e-01 -7.29229823e-02  2.10020676e-01  5.33612296e-02\n",
      "  3.54644097e-02 -4.07328866e-02 -4.33598608e-02  1.79720821e-03\n",
      " -1.02157041e-01  2.94042099e-02 -1.00497968e-01  3.11706811e-01\n",
      " -1.43234298e-01 -5.19070867e-03  5.18199056e-02  1.75101325e-01\n",
      "  1.35257393e-01  7.74593800e-02  2.63344347e-01  1.01621427e-01\n",
      "  2.52702218e-02 -2.47958656e-02  2.05387741e-01  1.30016625e-01\n",
      " -3.85808758e-02 -9.46183056e-02 -5.79164065e-02 -8.83732140e-02]\n"
     ]
    }
   ],
   "source": [
    "for word in q_input:\n",
    "    if word in modelw2v.wv:\n",
    "        print(modelw2v.wv[word])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.41277914]]\n"
     ]
    }
   ],
   "source": [
    "tfidf_q1 = vectorizer.transform([\"mày ăn cơm chưa?\"])\n",
    "tfidf_q2 = vectorizer.transform([\"quê mày ở đâu?\"])\n",
    "print(linear_kernel(tfidf_q1, tfidf_q2).flatten()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.41277914"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
